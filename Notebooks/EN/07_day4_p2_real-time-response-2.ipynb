{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c716ea",
   "metadata": {},
   "source": [
    "# Day 4, part 2: Outbreak estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb224de",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This practical is the second (out of two) part of a practical which simulates the early assessment and reconstruction of an Ebola Virus Disease (EVD) outbreak. \n",
    "Please make sure you have gone through **part 1** before starting **part 2**. \n",
    "In **part 2** of the practical, we introduce various aspects of analysis of the early stage of an outbreak, including growth rate estimation, contact tracing data, delays, and estimates of transmissibility. \n",
    "\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "By the end of this practical **part 2**, you should be able to:\n",
    "\n",
    "- Estimate & interpret the growth rate & doubling time of the epidemic\n",
    "\n",
    "- Estimate the serial interval from data on pairs infector / infected individuals\n",
    "\n",
    "- Estimate & interpret the reproduction number of the epidemic\n",
    "\n",
    "- Forecast short-term future incidence\n",
    "\n",
    "## Context: A novel EVD outbreak in a fictional country in West Africa\n",
    "\n",
    "A new EVD outbreak has been notified in a fictional country in West Africa. The Ministry of Health is in charge of coordinating the outbreak response, and have contracted you as a consultant in epidemic analysis to inform the response in real time. You have already read in an done descriptive analysis of the data (**part 1** of the practical). Now let's do some statistical analyses! \n",
    "\n",
    "## Required packages \n",
    "\n",
    "The following packages, available on CRAN or github, are needed for this analysis.\n",
    "You should have installed them in **part 1** but if not, install necessary packages as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8ad25",
   "metadata": {},
   "source": [
    "Once the packages are installed, you may need to open a new R session. Then load the libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29dedb",
   "metadata": {
    "name": "load_library",
    "vscode": {
     "languageId": "r"
    },
    "warning": false
   },
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "library(outbreaks)\n",
    "library(incidence)\n",
    "library(epicontacts)\n",
    "library(distcrete)\n",
    "library(epitrix)\n",
    "library(EpiEstim)\n",
    "library(projections)\n",
    "library(ggplot2)\n",
    "library(magrittr)\n",
    "library(binom)\n",
    "library(ape)\n",
    "library(outbreaker2)\n",
    "library(here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5b75c",
   "metadata": {},
   "source": [
    "## Read in the data processed in [part 1](./real-time-response-1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07483ef3",
   "metadata": {},
   "source": [
    "<!--\n",
    "ZNK: These two chunks are needed because of the way the documents are structured\n",
    "in blogdown. The source that we edit is not the same as the site that is\n",
    "rendered. Everything in this directory will end up in the same directory as the\n",
    "\"static\" when the website is displayed, but the current directory structure is\n",
    "present when the practicals are built, so we have to do this silly \n",
    "song-and-dance to appease the directory gods.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f15de5",
   "metadata": {
    "name": "read_data_ni",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "i_daily <- readRDS(here(\"data/clean/i_daily.rds\"))\n",
    "i_weekly <- readRDS(here(\"data/clean/i_weekly.rds\"))\n",
    "linelist <- readRDS(here(\"data/clean/linelist.rds\"))\n",
    "linelist_clean <- readRDS(here(\"data/clean/linelist_clean.rds\"))\n",
    "contacts <- readRDS(here(\"data/clean/contacts.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46186903",
   "metadata": {},
   "source": [
    "## Estimating the growth rate using a log-linear model\n",
    "\n",
    "The simplest model of incidence is probably the log-linear model, i.e. a linear \n",
    "regression on log-transformed incidences. \n",
    "For this we will work with weekly incidence, to avoid having\n",
    "too many issues with zero incidence (which cannot be logged). \n",
    "\n",
    "Visualise the log-transformed incidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b7f74",
   "metadata": {
    "name": "log_transform_weekly",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(as.data.frame(i_weekly)) + \n",
    "  geom_point(aes(x = dates, y = log(counts))) + \n",
    "  scale_x_incidence(i_weekly) +\n",
    "  xlab(\"date\") +\n",
    "  ylab(\"log weekly incidence\") + \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8f851",
   "metadata": {},
   "source": [
    "What does this plot tell you about the epidemic?   \n",
    "\n",
    "In the `incidence` package, the function `fit` will estimate the parameters of this model from an incidence object (here, `i_weekly`). Apply it to the data and store the result in a new object called `f`. You can print and use `f` to derive estimates of the growth rate r and the doubling time, and add the corresponding model to the incidence plot:  \n",
    "\n",
    "Fit a log-linear model to the weekly incidence data:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181383f0",
   "metadata": {
    "name": "log_linear_full",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "f <- incidence::fit(i_weekly)\n",
    "f\n",
    "plot(i_weekly, fit = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbae27d",
   "metadata": {},
   "source": [
    "Looking at the plot and fit, do you think this is a reasonable fit?   \n",
    "\n",
    "## Finding a suitable threshold date for the log-linear model, based on the observed delays\n",
    "\n",
    "Using the plot of the log(incidence) that you plotted above, and thinking about why exponential growth may not be observed in the most recent weeks, choose a threshold date and fit the log-linear model to a suitable section of the epicurve where you think we can more reliably estimate the growth rate, r, and the doubling time.  \n",
    "\n",
    "You may want to examine how long after onset of symptoms cases are hospitalised; \n",
    "this may inform the threshold date you choose, as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded84382",
   "metadata": {
    "name": "delays_in_reporting",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(as.numeric(linelist_clean$date_of_hospitalisation - linelist_clean$date_of_onset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c87039",
   "metadata": {
    "eval": false,
    "name": "n_weeks_to_remove",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# how many weeks should we discard at the end of the epicurve\n",
    "n_weeks_to_discard <- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2980bdc",
   "metadata": {
    "name": "trunc_incidence",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "min_date <- min(i_daily$dates)\n",
    "max_date <- max(i_daily$dates) - n_weeks_to_discard * 7\n",
    "# weekly truncated incidence\n",
    "i_weekly_trunc <- subset(i_weekly, \n",
    "                         from = min_date, \n",
    "                         to = max_date) # discard last few weeks of data\n",
    "# daily truncated incidence (not used for the linear regression but may be used later)\n",
    "i_daily_trunc <- subset(i_daily, \n",
    "                         from = min_date, \n",
    "                         to = max_date) # remove last two weeks of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c7686",
   "metadata": {},
   "source": [
    "Refit and plot your log-linear model as before but using the truncated data `i_weekly_trunc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0027d",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "fit_truncated",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "f <- incidence::fit(i_weekly_trunc)\n",
    "f\n",
    "plot(i_weekly_trunc, fit = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8fb489",
   "metadata": {},
   "source": [
    "Look at the summary statistics of your fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b275b4",
   "metadata": {
    "name": "fit_summary",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(f$model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979129c6",
   "metadata": {},
   "source": [
    "You can look at the goodness of fit (Rsquared), the estimated slope (growth rate)\n",
    "and the corresponding doubling time as below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45b211",
   "metadata": {
    "name": "growth_rate",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# does the model fit the data well? \n",
    "adjRsq_model_fit <- summary(f$model)$adj.r.squared\n",
    "# what is the estimated growth rate of the epidemic?\n",
    "daily_growth_rate <- f$model$coefficients['dates.x']\n",
    "# confidence interval:\n",
    "daily_growth_rate_CI <- confint(f$model, 'dates.x', level=0.95)\n",
    "# what is the doubling time of the epidemic? \n",
    "doubling_time_days <- log(2) / daily_growth_rate\n",
    "# confidence interval:\n",
    "doubling_time_days_CI <- log(2) / rev(daily_growth_rate_CI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204181b",
   "metadata": {},
   "source": [
    "Although the log-linear is a simple and quick method for early epidemic assessment, care must be taken to only fit to the point that there is epidemic growth. Note that it may be difficult to define this point.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12809a",
   "metadata": {},
   "source": [
    "## Contact Tracing - Looking at contacts\n",
    "\n",
    "Contact tracing is one of the pillars of an Ebola outbreak response. This involves identifying and following up any at risk individuals who have had contact with a known case (i.e. may have been infected). For Ebola, contacts are followed up for 21 days (the upper bound of the incubation period). This ensures that contacts who become symptomatic can be isolated quickly, reducing the chance of further transmission. We use the full linelist here rather than `linelist_clean` where we discarded entries with errors in the dates. However, the contact may still be valid.\n",
    "\n",
    "Using the function `make_epicontacts` in the `epicontacts` package, create a new `epicontacts` object called `epi_contacts`. Make sure you check the column names of the relevant `to` and `from` arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d158c",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "epicontacts",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "epi_contacts <- make_epicontacts(linelist = linelist, contacts = contacts, \n",
    "                                 id = \"case_id\", # name of identifier in linelist\n",
    "                                 from = \"infector\", # name of 'from' col in the contacts\n",
    "                                 to = \"case_id\",  # name of 'to' col in the contacts\n",
    "                                 directed = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fa77f",
   "metadata": {
    "name": "show_output_contacts",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "epi_contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642afb15",
   "metadata": {},
   "source": [
    "You can easily plot these contacts, but with a little bit of tweaking (see `?vis_epicontacts`) you can customise for example shapes by gender and arrow colours by source of exposure (or other variables of interest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459e16d",
   "metadata": {
    "name": "table_contact_type",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# for example, look at the reported source of infection of the contacts.\n",
    "table(epi_contacts$contacts$source, useNA = \"ifany\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734356f",
   "metadata": {
    "eval": false,
    "name": "plot_contacts",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- plot(epi_contacts, node_shape = \"gender\", shapes = c(m = \"male\", f = \"female\"), node_color = \"gender\", edge_color = \"source\", selector = FALSE)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd733c04",
   "metadata": {
    "lines_to_next_cell": 0,
    "name": "plot_contacts-ns",
    "tags": [
     "remove_input"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- plot(epi_contacts, node_shape = \"gender\", shapes = c(m = \"male\", f = \"female\"), node_color = \"gender\", edge_color = \"source\", selector = FALSE)\n",
    "#learn::save_and_use_widget(p, 'real-time-response-2-nework.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad346c1",
   "metadata": {},
   "source": [
    "Using the function `match` (see `?match`) check that the visualised contacts are indeed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4a137",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "check_contact_cases",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "match(contacts$case_id, linelist$case_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ae570",
   "metadata": {},
   "source": [
    "Once you are happy that these are all indeed cases, look at the network:  \n",
    "\n",
    "- does it look like there is super-spreading (heterogeneous transmission)?\n",
    "- looking at the gender of the cases, can you deduce anything from this? Are there any visible differences by gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fc2a2",
   "metadata": {},
   "source": [
    "## Estimating transmissibility (`$R$`)  \n",
    "\n",
    "### Branching process model  \n",
    "\n",
    "The transmissibility of the disease can be assessed through the estimation of the reproduction number R, defined as the expected number of secondary cases per infected case. In the early stages of an outbreak, and assuming a large population with no immunity, this quantity is also the basic reproduction number $$R_0$$, i.e. $$R$$ in a large fully susceptible population.  \n",
    "\n",
    "The package `EpiEstim` implements a Bayesian estimation of $$R$$, using dates of onset of symptoms and information on the serial interval distribution, i.e. the distribution of time from symptom onset in a case and symptom onset in their infector (see Cori et al., 2013, AJE 178: 1505–1512).\n",
    "\n",
    "Briefly, `EpiEstim` uses a simple model describing incidence on a given day as Poisson distributed, with a mean determined by the total force of infection on that day:\n",
    "\n",
    "$$ I_t  ∼  Poisson(\\lambda_t)$$\n",
    "\n",
    "where $$I_t$$ is the incidence (based on symptom onset) on day $$t$$ and $$\\lambda_t$$ is the force of infection on that day. Noting R the reproduction number and w() the discrete serial interval distribution, we have:\n",
    "\n",
    " $$\\lambda_t = R \\sum_{s=1}^t I_sw(t-s)$$\n",
    "\n",
    "The likelihood (probability of observing the data given the model and parameters) is defined as a function of R:\n",
    "\n",
    " $$L(I) = p(I|R) = \\prod_{t = 1}^{T} f_P(I_t, \\lambda_t)$$\n",
    "\n",
    "where $$f_P(.,\\mu)$$ is the probability mass function of a Poisson distribution with mean $$\\mu$$.\n",
    "\n",
    "### Estimating the serial interval\n",
    "\n",
    "As data was collected on pairs of infector and infected individuals, this should be sufficient to estimate the serial interval distribution. If that was not the case, we could have used data from past outbreaks instead.  \n",
    "\n",
    "Use the function `get_pairwise` can be used to extract the serial interval (i.e. the difference in date of onset between infectors and infected individuals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fa08c",
   "metadata": {
    "name": "si_estim",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "si_obs <- get_pairwise(epi_contacts, \"date_of_onset\")\n",
    "summary(si_obs)\n",
    "## Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
    "## 1.000   5.000   6.500   9.117  12.250  30.000 \n",
    "hist(si_obs, breaks = 0:30,\n",
    "     xlab = \"Days after symptom onset\", ylab = \"Frequency\",\n",
    "     main = \"Serial interval (empirical distribution)\",\n",
    "     col = \"grey\", border = \"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6c6f7",
   "metadata": {},
   "source": [
    "What do you think of this distribution? Make any adjustment you would deem necessary, and then use the function `fit_disc_gamma` from the package `epitrix` to fit a discretised Gamma distribution to these data. Your results should approximately look like:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c0aec",
   "metadata": {
    "name": "fit_gamma",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "si_fit <- fit_disc_gamma(si_obs, w = 1)\n",
    "si_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700eff42",
   "metadata": {},
   "source": [
    "`si_fit` contains various information about the fitted delays, including the estimated distribution in the `$distribution` slot. You can compare this distribution to the empirical data in the following plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aba06c",
   "metadata": {
    "name": "compare_empirical",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "si <- si_fit$distribution\n",
    "si\n",
    "\n",
    "## compare fitted distribution\n",
    "hist(si_obs, xlab = \"Days after symptom onset\", ylab = \"Frequency\",\n",
    "     main = \"Serial interval: fit to data\", col = \"salmon\", border = \"white\",\n",
    "     50, ylim = c(0, 0.15), freq = FALSE, breaks = 0:35)\n",
    "points(0:60, si$d(0:60), col = \"#9933ff\", pch = 20)\n",
    "points(0:60, si$d(0:60), col = \"#9933ff\", type = \"l\", lty = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77947b11",
   "metadata": {},
   "source": [
    "Would you trust this estimation of the generation time? How would you compare it to actual estimates from the West African EVD outbreak (WHO Ebola Response Team (2014) NEJM 371:1481–1495) with a mean of 15.3 days and a standard deviation 9.3 days?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd29235",
   "metadata": {},
   "source": [
    "### Estimation of the Reproduction Number\n",
    "\n",
    "Now that we have estimates of the serial interval, we can use this information to estimate transmissibility of the disease (as measured by `$R_0$`). Make sure you use a daily (not weekly) incidence object truncated to the period where you have decided there is exponential growth (`i_daily_trunc`).  \n",
    "\n",
    "Using the estimates of the mean and standard deviation of the serial interval you just obtained, use the function `estimate_R` to estimate the reproduction number  (see `?estimate_R`) and store the result in a new object `R`.  \n",
    "\n",
    "Before using `estimate_R`, you need to create a `config` object using the `make_config` function, where you will specify the time window where you want to estimate the reproduction number as well as the `mean_si` and `std_si` to use. For the time window, use `t_start = 2` (you can only estimate R from day 2 onwards as you are conditioning on the past observed incidence) and specify `t_end = length(i_daily_trunc$counts)` to estimate R up to the last date of your truncated incidence `i_daily_trunc`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca73227",
   "metadata": {
    "name": "config",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "config <- make_config(mean_si = si_fit$mu, # mean of the si distribution estimated earlier\n",
    "                      std_si = si_fit$sd,  # standard deviation of si dist estimated earlier\n",
    "                      t_start = 2,         # starting day of time window\n",
    "                      t_end = length(i_daily_trunc$counts)) # final day of time window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c6c44",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "calc_R",
    "vscode": {
     "languageId": "r"
    },
    "warning": false
   },
   "outputs": [],
   "source": [
    "R <- estimate_R(i_daily_trunc, method = \"parametric_si\", config = config)\n",
    "plot(R, legend = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1fcbb",
   "metadata": {},
   "source": [
    "Extract the median and 95% credible intervals (95%CrI) for the reproduction number as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78203dba",
   "metadata": {
    "name": "calc_R2",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "R_median <- R$R$`Median(R)`\n",
    "R_CrI <- c(R$R$`Quantile.0.025(R)`, R$R$`Quantile.0.975(R)`)\n",
    "R_median\n",
    "R_CrI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c90388",
   "metadata": {},
   "source": [
    "Interpret these results: what do you make of the reproduction number? What does it reflect? Based on the last part of the epicurve, some colleagues suggest that incidence is going down and the outbreak may be under control. What is your opinion on this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de10c461",
   "metadata": {},
   "source": [
    "Note that you could have estimated R0 directly from the growth rate and the serial interval, \n",
    "using the formula described in Wallinga and Lipsitch, Proc Biol Sci, 2007: \n",
    "$$R_0 = \\frac{1}{\\int_{s=0}^{+\\infty}e^{-rs}w(s)ds}$$ , and implemented in the function `r2R0` of the `epitrix` package. Although this may seem like a complicated formula, the reasoning behind it is simple and illustrated in the figure below: for an observed exponentially growing incidence curve, \n",
    "if you know the serial interval, you can derive the reproduction number. \n",
    "\n",
    "![Estimating R0 from the growth rate and the serial interval.](../static/img/R0fromr.png)\n",
    "\n",
    "Compared to the figure above, there is uncertainty in the growth rate r, and the serial interval has a full distribution rather than a single value. This can be accounted for in estimating R as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a83f63",
   "metadata": {
    "name": "R_from_growth_rate",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# generate a sample of R0 estimates from the growth rate and serial interval we estimated above \n",
    "R_sample_from_growth_rate <- lm2R0_sample(f$model, # log-linear model which contains our estimates of the growth rate r\n",
    "                                          si$d(1:100), # serial interval distribution (truncated after 100 days)\n",
    "                                          n = 1000) # desired sample size\n",
    "# plot these:\n",
    "hist(R_sample_from_growth_rate)\n",
    "# what is the median?\n",
    "R_median_from_growth_rate <- median(R_sample_from_growth_rate)\n",
    "R_median_from_growth_rate # compare with R_median\n",
    "# what is the 95%CI?\n",
    "R_CI_from_growth_rate <- quantile(R_sample_from_growth_rate, c(0.025, 0.975))\n",
    "R_CI_from_growth_rate # compare with R_CrI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c078d",
   "metadata": {},
   "source": [
    "Note the above estimates are slighlty different from those obtained using the branching process model. \n",
    "There are a few reasons for this. \n",
    "First, you used more detailed data (daily vs weekly incidence) for the branching process (EpiEstim) estimate. \n",
    "Furthermore, the log-linear model puts the same weight on all data points, whereas the branching process model puts a different weight on each data point (depending on the incidence observed at each time step). \n",
    "This may lead to slighlty different R estimates. \n",
    "\n",
    "## Short-term incidence forecasting  \n",
    "\n",
    "The function `project` from the package `projections` can be used to simulate plausible epidemic trajectories by simulating daily incidence using the same branching process as the one used to estimate `$R$` in `EpiEstim`. All that is needed is one, or several values of `$R$` and a serial interval distribution, stored as a `distcrete` object.  \n",
    "\n",
    "Here, we first illustrate how we can simulate 5 random trajectories using a fixed value of `$R$` = `r signif(R_median, 3)`, the median estimate of R from above.  \n",
    "Use the same daily truncated incidence object as above to simulate future incidence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4d8c2",
   "metadata": {
    "name": "projections",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#?project\n",
    "small_proj <- project(i_daily_trunc,# incidence object \n",
    "                      R = R_median, # R estimate to use\n",
    "                      si = si,      # serial interval distribution\n",
    "                      n_sim = 5,    # simulate 5 trajectories\n",
    "                      n_days = 10,  # over 10 days\n",
    "                      R_fix_within = TRUE) # keep the same value of R every day\n",
    "\n",
    "# look at each projected trajectory (as columns):\n",
    "as.matrix(small_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d500d",
   "metadata": {},
   "source": [
    "Using the same principle, generate 1,000 trajectories for the next 2 weeks, using a range of plausible values of `$R$`.  \n",
    "The posterior distribution of R is gamma distributed (see Cori et al. AJE 2013) so you can use the `rgamma` function to randomly draw values from that distribution. You will also need to use the function `gamma_mucv2shapescale` from the `epitrix` package as shown below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067c7d2",
   "metadata": {
    "name": "sampling_posterior_R",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_R <- function(R, n_sim = 1000)\n",
    "{\n",
    "  mu <- R$R$`Mean(R)`\n",
    "  sigma <- R$R$`Std(R)`\n",
    "  Rshapescale <- gamma_mucv2shapescale(mu = mu, cv = sigma / mu)\n",
    "  R_sample <- rgamma(n_sim, shape = Rshapescale$shape, scale = Rshapescale$scale)\n",
    "  return(R_sample)\n",
    "}\n",
    "\n",
    "R_sample <- sample_R(R, 1000) # sample 1000 values of R from the posterior distribution\n",
    "hist(R_sample, col = \"grey\")  # plot histogram of sample\n",
    "abline(v = R_median, col = \"red\") # show the median estimated R as red solid vertical line\n",
    "abline(v = R_CrI, col = \"red\", lty = 2) # show the 95%CrI of R as red dashed vertical lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a5533",
   "metadata": {},
   "source": [
    "Store the results of your new projections in an object called `proj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52ca43",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "projections2",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "proj <- project(x = i_daily_trunc, \n",
    "                R = R_sample, # now using a sample of R values\n",
    "                si = si, \n",
    "                n_sim = 1000, \n",
    "                n_days = 14, # project over 2 weeks\n",
    "                R_fix_within = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e801c",
   "metadata": {},
   "source": [
    "You can visualise the projections as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc1781",
   "metadata": {
    "name": "plot_projections",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(i_daily_trunc) %>% add_projections(proj, c(0.025, 0.5, 0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e371d2",
   "metadata": {},
   "source": [
    "How would you interpret the following summary of the projections?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56902800",
   "metadata": {
    "name": "interpret_results",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "apply(proj, 1, summary)\n",
    "apply(proj, 1, function(x) mean(x > 0)) # proportion of trajectories with at least \n",
    "                                        # one case on each given day\n",
    "\n",
    "apply(proj, 1, mean) # mean daily number of cases \n",
    "\n",
    "apply(apply(proj, 2, cumsum), 1, summary) # projected cumulative number of cases in \n",
    "                                          # the next two weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6adf1",
   "metadata": {},
   "source": [
    "According to these results, what are the chances that more cases will appear in the near future? Is this outbreak being brought under control? Would you recommend scaling up / down the response? Is this consistent with your estimate of $$R$$?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093913d",
   "metadata": {},
   "source": [
    "## Pause !\n",
    "\n",
    "Please let a demonstrator know when you have reached this point before proceeding further. \n",
    "\n",
    "## Accounting for uncertainty in the serial interval estimates when estimating the reproduction number\n",
    "\n",
    "Note that this section is independent from the following ones, please skip if you don'thave time. \n",
    "\n",
    "EpiEstim allows to explicitly account for the uncertainty in the serial interval estimates because of limited sample size of pairs of infector/infected individuals. Note that it also allows accounting for uncertainty on the dates of symptom onset for each of these pairs (which is not needed here). \n",
    "\n",
    "Use the `method = \"si_from_data\"` option in `estimate_R`. \n",
    "To use this option, you need to create a data frame with 4 columns: \n",
    "`EL`, `ER`, `SL` and `SR` for the left (L) and right (R) bounds of the observed time of symptoms in the infector (E) and infected (S for secondary) cases. Here we derive this from `si_obs` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ca13c",
   "metadata": {
    "name": "si_data",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "si_data <- data.frame(EL = rep(0L, length(si_obs)), \n",
    "                      ER = rep(1L, length(si_obs)), \n",
    "                      SL = si_obs, SR = si_obs + 1L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd9d07",
   "metadata": {},
   "source": [
    "We can then feed this into `estimate_R` (but this will take some time to run as it estimates the serial interval distribution using an MCMC and fully accounts for the uncertainty in the serial interval to estimate the reproduction number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9336a",
   "metadata": {
    "cache": true,
    "name": "R_variableSI",
    "vscode": {
     "languageId": "r"
    },
    "warning": false
   },
   "outputs": [],
   "source": [
    "config <- make_config(t_start = 2, \n",
    "                      t_end = length(i_daily_trunc$counts))\n",
    "R_variableSI <- estimate_R(i_daily_trunc, method = \"si_from_data\", \n",
    "                           si_data = si_data,\n",
    "                           config = config)\n",
    "# checking that the MCMC converged: \n",
    "R_variableSI$MCMC_converged\n",
    "# and plotting the output:\n",
    "plot(R_variableSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642cbd9d",
   "metadata": {},
   "source": [
    "Look at the new median estimated R and 95%CrI: how different are they from your previous estimates? Do you think the size of the contacts dataset has had an impact on your results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbadae9",
   "metadata": {
    "name": "summary_R_variableSI",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "R_variableSI_median <- R_variableSI$R$`Median(R)`\n",
    "R_variableSI_CrI <- c(R_variableSI$R$`Quantile.0.025(R)`, R_variableSI$R$`Quantile.0.975(R)`)\n",
    "R_variableSI_median\n",
    "R_variableSI_CrI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e975cbc",
   "metadata": {},
   "source": [
    "## Estimating time-varying transmissibility  \n",
    "\n",
    "When the assumption that ($$R$$) is constant over time becomes untenable, an alternative is to estimating time-varying transmissibility using the instantaneous reproduction number ($$R_t$$). This approach, introduced by Cori et al. (2013), is also implemented in the package `EpiEstim`. It estimates ($$R_t$$) for a custom time windows (default is a succession of sliding time windows), using the same Poisson likelihood described above. In the following, we estimate transmissibility for 1-week sliding time windows (the default of `estimate_R`):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0dfae",
   "metadata": {
    "name": "config_Rt",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "config = make_config(list(mean_si = si_fit$mu, std_si = si_fit$sd))  \n",
    "# t_start and t_end are automatically set to estimate R over 1-week sliding windows by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda016b3",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "timevarying_r",
    "vscode": {
     "languageId": "r"
    },
    "warning": false
   },
   "outputs": [],
   "source": [
    "Rt <- estimate_R(incid = i_daily_trunc,      # incidence object\n",
    "                 method = \"parametric_si\",   # use parametric serial interval\n",
    "                 config = config)            # config specified above\n",
    "\n",
    "# look at the most recent Rt estimates:\n",
    "tail(Rt$R[, c(\"t_start\", \"t_end\", \"Median(R)\", \n",
    "             \"Quantile.0.025(R)\", \"Quantile.0.975(R)\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d48f6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Plot the estimate of `$R$` over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4058d",
   "metadata": {
    "name": "new_EpiEstim",
    "vscode": {
     "languageId": "r"
    },
    "warnings": false
   },
   "outputs": [],
   "source": [
    "plot(Rt, legend = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ea984",
   "metadata": {},
   "source": [
    "How would you interpret this result? What is the caveat of this representation?\n",
    "\n",
    "What would you have concluded if instead of using `i_daily_trunc` as above, you had used the entire epidemics curve io.e. `i_daily`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fb52d",
   "metadata": {
    "echo": "#R_CODE#params$full_version",
    "name": "timevarying_r_whole_incid",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Rt_whole_incid <- estimate_R(incid = i_daily, \n",
    "                             method = \"parametric_si\", \n",
    "                             config = config) \n",
    "\n",
    "tail(Rt_whole_incid$R[, c(\"t_start\", \"t_end\", \n",
    "                         \"Median(R)\", \"Quantile.0.025(R)\", \"Quantile.0.975(R)\")])  \n",
    "# the above incorrectly infers that the recent transmissibility is <1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75d5e2",
   "metadata": {
    "eval": "#R_CODE#params$full_version",
    "name": "Rt_plot",
    "results": "#R_CODE#render_snippet",
    "tags": [
     "remove_input"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"- the above assumes constant R within sliding time-window\")  \n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "cache,echo,warning,name,warnings,results,tags,eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
